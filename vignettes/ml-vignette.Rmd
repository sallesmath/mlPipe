---
title: "mlPipe-vignette"
author: "Matheus Salles"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ml-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Loading necessary packages:
```{r setup}
library(mlPipe)
library(usethis)
library(devtools)
library(caret)
library(mlbench)
library(caretEnsemble)
```

### Package datasets
Inspect datasets to use mlPipe functions. In this tutorial we're going to use a dataset present in mlbench and caret.

If you want to use other datasets, it is important that you organize your data in a dataframe with samples in rows and characteristics of interest in columns. Also, for the package to work properly, the dependent variable MUST be represented in the last column of your dataframe.
```{r}
data(PimaIndiansDiabetes)

# rename dataset to keep code below generic

my_df <- PimaIndiansDiabetes
head(my_df)
```

--------------

### Package functions
In this tutorial, we're going to start by doing the input file configuration and training our data with a specific machine learning model
```{r}
# Train your data with specific parameters. In this case, we're going to use:
# 80%/20% split between training and test set
# Machine learning algorithm: Linear discriminant analysis (lda)
# Evaluation metric: Accuracy
# Setting a seed: 42
# Resampling method: Repeated cross-validation ("repeatedcv")
my_model <- ml.train(my_df, 0.8, "lda", "Accuracy", 42, "repeatedcv")
my_model
```

Using another function from our package you can also train multiple models at the same time. ml.trainlist wiil generate a list of trained machine learning models.
```{r}
# Train your data with specific parameters. In this case, we're going to use:
# 80%/20% split between training and test set
# Machine learning algorithms: Random Forest (rf), Linear discriminant analysis (lda), Generalized Linear Model (glm), K-Nearest Neighbour (knn)
# Evaluation metric: Accuracy
# Setting a seed: 42
# Resampling method: Repeated cross-validation ("repeatedcv")
my_models <- ml.trainlist(my_df, 0.8, algorithm = c("rf", "lda", "glm", "knn"), metric = "Accuracy", seed = 42, resampling = "repeatedcv")
my_models
```

Now that you have a list of trained machine learning models, it's useful to visualize them. In order to do so, you can use the following function
```{r}
# The next functions provide methods for collection, analyzing and visualizing a set of resampling results from a common data set.
results <- resamples(my_models)
summary(results)
# Now we're ready to plot our trained data
# The available graphic options in our package are: bwplot, dotplot, parallelplot and splom. In this tutorial we're going to use bwplot:
ml.graphic(ml_result = results, graphic = "dotplot")
```
